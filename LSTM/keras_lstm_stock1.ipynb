{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM 학습용을 위한 데이터 생성. window개념 포함.\n",
    "def getSeriesData(data, window_size, elementdim=1, predict_size=1):\n",
    "  '''\n",
    "  window_size 만큼의 데이터로 다음 데이터를 예측하기 위한 학습데이터 생성\n",
    "  :param data: [1,2,3,4,5]\n",
    "  :param window_size:\n",
    "  :param elementdim:\n",
    "  :return: x=[1,2,3], y=[4], x=[2,3,4], y=[5]\n",
    "  '''\n",
    "  assert window_size < len(data)\n",
    "  num = len(data) - window_size - predict_size + 1\n",
    "  xdata = [data[i:i + window_size] for i in range(num)]\n",
    "  ydata = [data[i + window_size:i + window_size + predict_size] for i in range(num)]\n",
    "  \n",
    "  x = np.array(xdata, dtype=np.float32).reshape((-1, window_size, elementdim))\n",
    "  y = np.array(ydata, dtype=np.float32).reshape((-1, predict_size * elementdim))\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용, 검증용, 테스트용 분할하기\n",
    "def split_data(data, val_size=0.15, test_size=0.15):\n",
    "  \"\"\"\n",
    "  splits data to training, validation and testing parts\n",
    "  \"\"\"\n",
    "  ntest = int(round(len(data) * (1 - test_size)))\n",
    "  nval = int(round(ntest * (1 - val_size)))\n",
    "  \n",
    "  train, validation, test = np.split(data, [nval, ntest])\n",
    "  \n",
    "  return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.columns :  Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "MAX_PRICE :  175.11\n",
      "TRAIN (1460, 1)\n",
      "TEST (303, 1)\n",
      "TRAIN X (1430, 30, 1)\n",
      "TRAIN Y (1430, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('apple.csv', header=0)\n",
    "print('df.columns : ', df.columns)\n",
    "MAX_PRICE = df.Open.max()\n",
    "print('MAX_PRICE : ', MAX_PRICE)\n",
    "df = df[df.Open != 0][['Open']]\n",
    "df.Open = df.Open / MAX_PRICE\n",
    "xy = df.as_matrix()\n",
    "\n",
    "train, validation, test = split_data(xy)\n",
    "WINDOWSIZE = 30\n",
    "train_x, train_y = getSeriesData(train, WINDOWSIZE, elementdim=1)\n",
    "valid_x, valid_y = getSeriesData(validation, WINDOWSIZE, elementdim=1)\n",
    "test_x, test_y = getSeriesData(test, WINDOWSIZE, elementdim=1)\n",
    "\n",
    "print('TRAIN', train.shape)\n",
    "print('TEST', test.shape)\n",
    "print('TRAIN X', train_x.shape)\n",
    "print('TRAIN Y', train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "hidden_nodes = 60\n",
    "model.add(LSTM(hidden_nodes, input_shape=(WINDOWSIZE, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 학습과정 설정하기\n",
    "import keras\n",
    "#opt = keras.optimizers.SGD(lr=0.1)\n",
    "opt = keras.optimizers.Adam(lr=0.2, decay=0.99)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "class mykerasCB(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, arga, argb):\n",
    "        print('LR=', tf.to_float(self.model.optimizer.lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1430 samples, validate on 228 samples\n",
      "Epoch 1/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 25.4878LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 2s 1ms/step - loss: 23.4515 - val_loss: 7.0426\n",
      "Epoch 2/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 6.3211LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 351us/step - loss: 6.0725 - val_loss: 3.2835\n",
      "Epoch 3/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 1.3859LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 335us/step - loss: 1.2840 - val_loss: 0.0971\n",
      "Epoch 4/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.3207LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 327us/step - loss: 0.3298 - val_loss: 0.0509\n",
      "Epoch 5/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.4447LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 357us/step - loss: 0.4364 - val_loss: 0.0334\n",
      "Epoch 6/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.3500LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 321us/step - loss: 0.3447 - val_loss: 0.0018\n",
      "Epoch 7/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.3137LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 365us/step - loss: 0.3139 - val_loss: 0.0181\n",
      "Epoch 8/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2699LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 376us/step - loss: 0.2683 - val_loss: 0.0346\n",
      "Epoch 9/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2667LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 310us/step - loss: 0.2688 - val_loss: 0.0364\n",
      "Epoch 10/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2723LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 327us/step - loss: 0.2711 - val_loss: 0.0333\n",
      "Epoch 11/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2852LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 344us/step - loss: 0.2789 - val_loss: 0.0301\n",
      "Epoch 12/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2865LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 357us/step - loss: 0.2889 - val_loss: 0.0279\n",
      "Epoch 13/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2815LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 498us/step - loss: 0.2793 - val_loss: 0.0264\n",
      "Epoch 14/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2766LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 472us/step - loss: 0.2700 - val_loss: 0.0244\n",
      "Epoch 15/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2569LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 332us/step - loss: 0.2609 - val_loss: 0.0250\n",
      "Epoch 16/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2639LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 351us/step - loss: 0.2665 - val_loss: 0.0264\n",
      "Epoch 17/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2751LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 326us/step - loss: 0.2745 - val_loss: 0.0276\n",
      "Epoch 18/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2704LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 389us/step - loss: 0.2686 - val_loss: 0.0287\n",
      "Epoch 19/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2795LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 335us/step - loss: 0.2779 - val_loss: 0.0297\n",
      "Epoch 20/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2718LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 347us/step - loss: 0.2705 - val_loss: 0.0296\n",
      "Epoch 21/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2756LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 358us/step - loss: 0.2739 - val_loss: 0.0292\n",
      "Epoch 22/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2762LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 321us/step - loss: 0.2712 - val_loss: 0.0285\n",
      "Epoch 23/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2672LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 357us/step - loss: 0.2695 - val_loss: 0.0295\n",
      "Epoch 24/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2394LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 526us/step - loss: 0.2421 - val_loss: 0.0292\n",
      "Epoch 25/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2582LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 399us/step - loss: 0.2551 - val_loss: 0.0298\n",
      "Epoch 26/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2406LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 364us/step - loss: 0.2506 - val_loss: 0.0298\n",
      "Epoch 27/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2451LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 332us/step - loss: 0.2427 - val_loss: 0.0299\n",
      "Epoch 28/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2537LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 333us/step - loss: 0.2540 - val_loss: 0.0318\n",
      "Epoch 29/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2703LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 366us/step - loss: 0.2702 - val_loss: 0.0313\n",
      "Epoch 30/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2540LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 350us/step - loss: 0.2532 - val_loss: 0.0306\n",
      "Epoch 31/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2655LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 383us/step - loss: 0.2648 - val_loss: 0.0306\n",
      "Epoch 32/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2496LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 478us/step - loss: 0.2483 - val_loss: 0.0294\n",
      "Epoch 33/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2495LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 419us/step - loss: 0.2438 - val_loss: 0.0281\n",
      "Epoch 34/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2429LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 365us/step - loss: 0.2447 - val_loss: 0.0291\n",
      "Epoch 35/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2484LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 317us/step - loss: 0.2466 - val_loss: 0.0293\n",
      "Epoch 36/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2425LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 321us/step - loss: 0.2424 - val_loss: 0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2592LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 341us/step - loss: 0.2519 - val_loss: 0.0297\n",
      "Epoch 38/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2568LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 373us/step - loss: 0.2542 - val_loss: 0.0302\n",
      "Epoch 39/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2323LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 413us/step - loss: 0.2304 - val_loss: 0.0298\n",
      "Epoch 40/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2518LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 365us/step - loss: 0.2495 - val_loss: 0.0295\n",
      "Epoch 41/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2243LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 334us/step - loss: 0.2252 - val_loss: 0.0297\n",
      "Epoch 42/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2456LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 352us/step - loss: 0.2478 - val_loss: 0.0300\n",
      "Epoch 43/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2493LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 392us/step - loss: 0.2476 - val_loss: 0.0295\n",
      "Epoch 44/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2497LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 358us/step - loss: 0.2505 - val_loss: 0.0296\n",
      "Epoch 45/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2399LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 319us/step - loss: 0.2461 - val_loss: 0.0299\n",
      "Epoch 46/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2402LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 432us/step - loss: 0.2353 - val_loss: 0.0299\n",
      "Epoch 47/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2572LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 387us/step - loss: 0.2602 - val_loss: 0.0299\n",
      "Epoch 48/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2406LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 307us/step - loss: 0.2397 - val_loss: 0.0308\n",
      "Epoch 49/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2452LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 407us/step - loss: 0.2488 - val_loss: 0.0305\n",
      "Epoch 50/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2541LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 337us/step - loss: 0.2574 - val_loss: 0.0310\n",
      "Epoch 51/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2331LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 391us/step - loss: 0.2381 - val_loss: 0.0317\n",
      "Epoch 52/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2470LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 343us/step - loss: 0.2489 - val_loss: 0.0313\n",
      "Epoch 53/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2221LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 334us/step - loss: 0.2239 - val_loss: 0.0319\n",
      "Epoch 54/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2483LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 303us/step - loss: 0.2458 - val_loss: 0.0328\n",
      "Epoch 55/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2426LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 389us/step - loss: 0.2410 - val_loss: 0.0325\n",
      "Epoch 56/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2372LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 303us/step - loss: 0.2363 - val_loss: 0.0314\n",
      "Epoch 57/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2433LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 377us/step - loss: 0.2420 - val_loss: 0.0303\n",
      "Epoch 58/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2361LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 297us/step - loss: 0.2292 - val_loss: 0.0302\n",
      "Epoch 59/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2509LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 297us/step - loss: 0.2495 - val_loss: 0.0306\n",
      "Epoch 60/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2397LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 314us/step - loss: 0.2374 - val_loss: 0.0305\n",
      "Epoch 61/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2375LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 307us/step - loss: 0.2369 - val_loss: 0.0303\n",
      "Epoch 62/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2271LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 303us/step - loss: 0.2272 - val_loss: 0.0310\n",
      "Epoch 63/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2379LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 299us/step - loss: 0.2375 - val_loss: 0.0315\n",
      "Epoch 64/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2396LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 330us/step - loss: 0.2386 - val_loss: 0.0312\n",
      "Epoch 65/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2479LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 304us/step - loss: 0.2477 - val_loss: 0.0308\n",
      "Epoch 66/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2372LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 367us/step - loss: 0.2356 - val_loss: 0.0299\n",
      "Epoch 67/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2255LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 303us/step - loss: 0.2278 - val_loss: 0.0292\n",
      "Epoch 68/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2488LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 309us/step - loss: 0.2448 - val_loss: 0.0295\n",
      "Epoch 69/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2370LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 306us/step - loss: 0.2381 - val_loss: 0.0307\n",
      "Epoch 70/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2254LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 327us/step - loss: 0.2269 - val_loss: 0.0309\n",
      "Epoch 71/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2245LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 334us/step - loss: 0.2229 - val_loss: 0.0317\n",
      "Epoch 72/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2233LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 348us/step - loss: 0.2241 - val_loss: 0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2209LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 451us/step - loss: 0.2218 - val_loss: 0.0308\n",
      "Epoch 74/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2267LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 327us/step - loss: 0.2263 - val_loss: 0.0301\n",
      "Epoch 75/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2303LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 310us/step - loss: 0.2328 - val_loss: 0.0307\n",
      "Epoch 76/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2203LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 409us/step - loss: 0.2211 - val_loss: 0.0312\n",
      "Epoch 77/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2238LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 412us/step - loss: 0.2211 - val_loss: 0.0323\n",
      "Epoch 78/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2398LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 361us/step - loss: 0.2436 - val_loss: 0.0329\n",
      "Epoch 79/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2258LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 309us/step - loss: 0.2326 - val_loss: 0.0312\n",
      "Epoch 80/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2281LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 361us/step - loss: 0.2250 - val_loss: 0.0304\n",
      "Epoch 81/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2307LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 317us/step - loss: 0.2289 - val_loss: 0.0300\n",
      "Epoch 82/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2246LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 358us/step - loss: 0.2269 - val_loss: 0.0298\n",
      "Epoch 83/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2133LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 310us/step - loss: 0.2121 - val_loss: 0.0302\n",
      "Epoch 84/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2185LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 406us/step - loss: 0.2129 - val_loss: 0.0302\n",
      "Epoch 85/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2099LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 294us/step - loss: 0.2098 - val_loss: 0.0304\n",
      "Epoch 86/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2272LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 407us/step - loss: 0.2243 - val_loss: 0.0302\n",
      "Epoch 87/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2243LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 297us/step - loss: 0.2250 - val_loss: 0.0301\n",
      "Epoch 88/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2085LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 377us/step - loss: 0.2080 - val_loss: 0.0301\n",
      "Epoch 89/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2303LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 344us/step - loss: 0.2272 - val_loss: 0.0297\n",
      "Epoch 90/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2120LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 288us/step - loss: 0.2136 - val_loss: 0.0287\n",
      "Epoch 91/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2260LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 334us/step - loss: 0.2252 - val_loss: 0.0289\n",
      "Epoch 92/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2166LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 439us/step - loss: 0.2150 - val_loss: 0.0288\n",
      "Epoch 93/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2309LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 326us/step - loss: 0.2303 - val_loss: 0.0282\n",
      "Epoch 94/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2103LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 303us/step - loss: 0.2139 - val_loss: 0.0274\n",
      "Epoch 95/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2128LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 408us/step - loss: 0.2106 - val_loss: 0.0276\n",
      "Epoch 96/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2129LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 434us/step - loss: 0.2091 - val_loss: 0.0279\n",
      "Epoch 97/100\n",
      "1144/1430 [=======================>......] - ETA: 0s - loss: 0.2340LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 350us/step - loss: 0.2306 - val_loss: 0.0284\n",
      "Epoch 98/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.1971LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 1s 367us/step - loss: 0.2051 - val_loss: 0.0287\n",
      "Epoch 99/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2072LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 320us/step - loss: 0.2028 - val_loss: 0.0284\n",
      "Epoch 100/100\n",
      "1287/1430 [==========================>...] - ETA: 0s - loss: 0.2087LR= Tensor(\"Adam_6/lr/read:0\", shape=(), dtype=float32)\n",
      "1430/1430 [==============================] - 0s 318us/step - loss: 0.2093 - val_loss: 0.0279\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "hist = model.fit(train_x, train_y, \n",
    "                 epochs=100, batch_size=int(train_x.shape[0] / 10), \n",
    "                 validation_data=(valid_x, valid_y), \n",
    "                 shuffle=True,\n",
    "                 callbacks=[mykerasCB()],\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.189480193041\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "testScore = model.evaluate(test_x, test_y, verbose=0)\n",
    "model.reset_states()\n",
    "print('Test Score: ', testScore)\n",
    "\n",
    "test_res = model.predict(test_x)\n",
    "\n",
    "#print(test_y[:10, 0])\n",
    "#print(test_res[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb03eb5d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(test_y[:, 0], label='actual')\n",
    "ax.plot(test_res[:, 0], label='nn')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
