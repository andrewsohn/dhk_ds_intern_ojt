{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrew-MB/DEV/08.PYTHON/01.WORKSPACE/slowcampus0202/env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/Andrew-MB/DEV/08.PYTHON/01.WORKSPACE/slowcampus0202/env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = w * x + b 함수\n",
    "def myfunc(x):\n",
    "  w = 2.3 # 기울기\n",
    "  b = 3.6 # y 절편.  점(0, 2.6)\n",
    "  # x 절편은 점(-2, 0)이 됨.\n",
    "  y = w * x + b\n",
    "  noise = random.random() * 0.2 # Noise\n",
    "  return y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.random() -- 0.0 ~ 1.0\n",
    "NUM_DATA = 20          # 데이터 갯수\n",
    "XVALUE = 5              # X값의 범위 (0.0 ~ 5.0)\n",
    "# type: python list\n",
    "xtrain = [random.random() * XVALUE for i in range(NUM_DATA)]\n",
    "xtrain.sort()            # sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain : [0.03934402017340355, 0.23073381000664694, 0.3191599464288458]\n",
      "ytrain : [3.8823997565672506, 4.237665613529607, 4.502078315349286]\n"
     ]
    }
   ],
   "source": [
    "ytrain = [myfunc(x) for x in xtrain]\n",
    "print('xtrain :',xtrain[:3])\n",
    "print('ytrain :',ytrain[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120d14cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# actual data 산점도\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xtrain, ytrain, label='actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlist.shape : (20,)\n",
      "ylist.shape : (20,)\n"
     ]
    }
   ],
   "source": [
    "# type 변환 python list -> numpy ndarray\n",
    "# type: numpy ndarray\n",
    "xtrain = np.array(xtrain)\n",
    "ytrain = np.array(ytrain)\n",
    "print('xlist.shape :',xtrain.shape)  # shape ==  (10,)\n",
    "print('ylist.shape :',ytrain.shape)  # shape ==  (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlist.shape : (20, 1)\n",
      "ylist.shape : (20, 1)\n"
     ]
    }
   ],
   "source": [
    "# tensor 에 맞추기 위해 reshape\n",
    "xtrain = xtrain.reshape((NUM_DATA, 1))  # shape ==  (10,1)\n",
    "ytrain = ytrain.reshape((NUM_DATA, 1))  # shape ==  (10,1)\n",
    "print('xlist.shape :', xtrain.shape)\n",
    "print('ylist.shape :', ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "W = tf.Variable(tf.random_normal([1,1], -1, 1), name='weight')\n",
    "B = tf.Variable(tf.random_normal([1], -1, 1), name='bias')\n",
    "Y2 = tf.matmul(X, W) + B   # [1,1]행렬 x [1,1]행렬 + [1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "# MSE = Mean Squared Error. 오차 제곱의 평균. (Y2-Y)**2의 평균\n",
    "cost_function = tf.reduce_mean(tf.square(Y2 - Y))\n",
    "# 옵티마이저\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "training = optimizer.minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss list\n",
    "history = []           # Record loss values for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0000] LOSS 112.37197 W [[5.663175]] bias [0.97100353]\n",
      "[0001] LOSS 50.40735 W [[1.8479357]] bias [-0.04707241]\n",
      "[0002] LOSS 23.426899 W [[4.2644176]] bias [0.91256255]\n",
      "[0003] LOSS 11.594794 W [[2.587488]] bias [0.55660045]\n",
      "[0004] LOSS 6.330553 W [[3.60706]] bias [1.0516073]\n",
      "[0005] LOSS 3.921598 W [[2.8576195]] bias [0.9735091]\n",
      "[0006] LOSS 2.7608151 W [[3.2756202]] bias [1.2595222]\n",
      "[0007] LOSS 2.1518185 W [[2.9297385]] bias [1.2939614]\n",
      "[0008] LOSS 1.7922266 W [[3.0898793]] bias [1.4823486]\n",
      "[0009] LOSS 1.5501821 W [[2.9207203]] bias [1.5585924]\n",
      "[0010] LOSS 1.3676836 W [[2.971418]] bias [1.6982468]\n",
      "[0011] LOSS 1.2187698 W [[2.8806586]] bias [1.7863959]\n",
      "[0012] LOSS 1.0914254 W [[2.8858922]] bias [1.8991184]\n",
      "[0013] LOSS 0.97974414 W [[2.8308105]] bias [1.9868629]\n",
      "[0014] LOSS 0.8805342 W [[2.8180618]] bias [2.0826714]\n",
      "[0015] LOSS 0.79184216 W [[2.7800035]] bias [2.1652465]\n",
      "[0016] LOSS 0.7123073 W [[2.7609885]] bias [2.2490036]\n",
      "[0017] LOSS 0.6408766 W [[2.7317257]] bias [2.3248515]\n",
      "[0018] LOSS 0.57667875 W [[2.7113595]] bias [2.399137]\n",
      "[0019] LOSS 0.5189609 W [[2.6871889]] bias [2.468036]\n",
      "[0020] LOSS 0.4670601 W [[2.6674607]] bias [2.5343943]\n",
      "[0021] LOSS 0.4203868 W [[2.6466513]] bias [2.5966547]\n",
      "[0022] LOSS 0.37841254 W [[2.628298]] bias [2.6561394]\n",
      "[0023] LOSS 0.34066352 W [[2.6099846]] bias [2.7122614]\n",
      "[0024] LOSS 0.30671415 W [[2.5932148]] bias [2.7656748]\n",
      "[0025] LOSS 0.27618212 W [[2.5769181]] bias [2.8162036]\n",
      "[0026] LOSS 0.24872306 W [[2.5617218]] bias [2.8642046]\n",
      "[0027] LOSS 0.22402754 W [[2.5471408]] bias [2.9096718]\n",
      "[0028] LOSS 0.2018178 W [[2.5334244]] bias [2.9528258]\n",
      "[0029] LOSS 0.18184325 W [[2.5203433]] bias [2.9937272]\n",
      "[0030] LOSS 0.16387929 W [[2.507986]] bias [3.032531]\n",
      "[0031] LOSS 0.14772323 W [[2.4962358]] bias [3.0693202]\n",
      "[0032] LOSS 0.13319342 W [[2.485113]] bias [3.1042154]\n",
      "[0033] LOSS 0.12012603 W [[2.4745514]] bias [3.1373038]\n",
      "[0034] LOSS 0.1083737 W [[2.464544]] bias [3.1686857]\n",
      "[0035] LOSS 0.09780436 W [[2.455048]] bias [3.1984446]\n",
      "[0036] LOSS 0.08829863 W [[2.4460466]] bias [3.2266674]\n",
      "[0037] LOSS 0.07974984 W [[2.4375072]] bias [3.2534313]\n",
      "[0038] LOSS 0.07206136 W [[2.429411]] bias [3.2788134]\n",
      "[0039] LOSS 0.06514679 W [[2.4217315]] bias [3.3028836]\n",
      "[0040] LOSS 0.05892812 W [[2.41445]] bias [3.3257108]\n",
      "[0041] LOSS 0.05333541 W [[2.4075437]] bias [3.3473585]\n",
      "[0042] LOSS 0.04830558 W [[2.4009948]] bias [3.3678882]\n",
      "[0043] LOSS 0.04378196 W [[2.3947837]] bias [3.3873572]\n",
      "[0044] LOSS 0.039713647 W [[2.3888938]] bias [3.4058206]\n",
      "[0045] LOSS 0.036054797 W [[2.383308]] bias [3.42333]\n",
      "[0046] LOSS 0.032764204 W [[2.3780107]] bias [3.439935]\n",
      "[0047] LOSS 0.029804831 W [[2.3729875]] bias [3.4556823]\n",
      "[0048] LOSS 0.027143305 W [[2.3682232]] bias [3.4706159]\n",
      "[0049] LOSS 0.024749627 W [[2.3637054]] bias [3.4847782]\n",
      "[0050] LOSS 0.02259695 W [[2.3594208]] bias [3.4982088]\n",
      "[0051] LOSS 0.020660905 W [[2.3553576]] bias [3.5109456]\n",
      "[0052] LOSS 0.018919704 W [[2.3515043]] bias [3.5230243]\n",
      "[0053] LOSS 0.01735377 W [[2.34785]] bias [3.5344791]\n",
      "[0054] LOSS 0.015945438 W [[2.344385]] bias [3.5453422]\n",
      "[0055] LOSS 0.014678856 W [[2.341098]] bias [3.555644]\n",
      "[0056] LOSS 0.013539763 W [[2.337982]] bias [3.565414]\n",
      "[0057] LOSS 0.012515277 W [[2.3350258]] bias [3.574679]\n",
      "[0058] LOSS 0.011593956 W [[2.3322232]] bias [3.5834653]\n",
      "[0059] LOSS 0.0107653495 W [[2.3295646]] bias [3.5917978]\n",
      "[0060] LOSS 0.010020143 W [[2.327044]] bias [3.5997]\n",
      "[0061] LOSS 0.009349902 W [[2.3246534]] bias [3.607194]\n",
      "[0062] LOSS 0.00874716 W [[2.322386]] bias [3.6143007]\n",
      "[0063] LOSS 0.008205047 W [[2.3202362]] bias [3.6210403]\n",
      "[0064] LOSS 0.0077175335 W [[2.318197]] bias [3.6274319]\n",
      "[0065] LOSS 0.007279077 W [[2.3162637]] bias [3.6334932]\n",
      "[0066] LOSS 0.006884762 W [[2.3144295]] bias [3.6392412]\n",
      "[0067] LOSS 0.0065301037 W [[2.312691]] bias [3.6446927]\n",
      "[0068] LOSS 0.0062111667 W [[2.3110416]] bias [3.6498623]\n",
      "[0069] LOSS 0.0059243133 W [[2.3094776]] bias [3.654765]\n",
      "[0070] LOSS 0.0056663402 W [[2.3079944]] bias [3.6594143]\n",
      "[0071] LOSS 0.0054343217 W [[2.306588]] bias [3.6638234]\n",
      "[0072] LOSS 0.0052256784 W [[2.3052537]] bias [3.6680048]\n",
      "[0073] LOSS 0.0050380128 W [[2.303989]] bias [3.6719701]\n",
      "[0074] LOSS 0.00486924 W [[2.3027892]] bias [3.6757307]\n",
      "[0075] LOSS 0.0047174646 W [[2.3016515]] bias [3.679297]\n",
      "[0076] LOSS 0.004580957 W [[2.3005726]] bias [3.682679]\n",
      "[0077] LOSS 0.0044581927 W [[2.2995496]] bias [3.6858861]\n",
      "[0078] LOSS 0.004347778 W [[2.2985792]] bias [3.6889277]\n",
      "[0079] LOSS 0.004248495 W [[2.2976592]] bias [3.6918123]\n",
      "[0080] LOSS 0.004159182 W [[2.2967863]] bias [3.6945477]\n",
      "[0081] LOSS 0.0040788734 W [[2.295959]] bias [3.697142]\n",
      "[0082] LOSS 0.0040066466 W [[2.295174]] bias [3.699602]\n",
      "[0083] LOSS 0.003941684 W [[2.2944298]] bias [3.701935]\n",
      "[0084] LOSS 0.0038832645 W [[2.293724]] bias [3.7041476]\n",
      "[0085] LOSS 0.003830722 W [[2.2930546]] bias [3.706246]\n",
      "[0086] LOSS 0.0037834633 W [[2.29242]] bias [3.7082357]\n",
      "[0087] LOSS 0.003740963 W [[2.2918177]] bias [3.7101228]\n",
      "[0088] LOSS 0.003702743 W [[2.291247]] bias [3.7119124]\n",
      "[0089] LOSS 0.0036683741 W [[2.2907054]] bias [3.7136095]\n",
      "[0090] LOSS 0.0036374584 W [[2.290192]] bias [3.715219]\n",
      "[0091] LOSS 0.003609656 W [[2.289705]] bias [3.7167454]\n",
      "[0092] LOSS 0.0035846536 W [[2.2892432]] bias [3.7181928]\n",
      "[0093] LOSS 0.0035621482 W [[2.2888055]] bias [3.7195656]\n",
      "[0094] LOSS 0.0035419278 W [[2.2883902]] bias [3.7208674]\n",
      "[0095] LOSS 0.003523744 W [[2.2879963]] bias [3.722102]\n",
      "[0096] LOSS 0.0035073876 W [[2.2876227]] bias [3.7232726]\n",
      "[0097] LOSS 0.0034926925 W [[2.2872689]] bias [3.7243829]\n",
      "[0098] LOSS 0.0034794323 W [[2.2869327]] bias [3.7254357]\n",
      "[0099] LOSS 0.003467545 W [[2.2866142]] bias [3.7264342]\n",
      "[0100] LOSS 0.0034568496 W [[2.286312]] bias [3.7273812]\n",
      "[0101] LOSS 0.0034472127 W [[2.2860258]] bias [3.7282794]\n",
      "[0102] LOSS 0.0034385715 W [[2.285754]] bias [3.729131]\n",
      "[0103] LOSS 0.0034307856 W [[2.2854962]] bias [3.7299387]\n",
      "[0104] LOSS 0.0034237714 W [[2.285252]] bias [3.7307048]\n",
      "[0105] LOSS 0.0034174682 W [[2.2850199]] bias [3.731431]\n",
      "[0106] LOSS 0.0034118188 W [[2.2848005]] bias [3.73212]\n",
      "[0107] LOSS 0.0034067289 W [[2.284592]] bias [3.7327733]\n",
      "[0108] LOSS 0.0034021344 W [[2.2843945]] bias [3.733393]\n",
      "[0109] LOSS 0.003398023 W [[2.2842069]] bias [3.7339804]\n",
      "[0110] LOSS 0.0033943162 W [[2.2840292]] bias [3.7345376]\n",
      "[0111] LOSS 0.0033909972 W [[2.2838604]] bias [3.735066]\n",
      "[0112] LOSS 0.0033879976 W [[2.283701]] bias [3.735567]\n",
      "[0113] LOSS 0.0033853077 W [[2.283549]] bias [3.7360423]\n",
      "[0114] LOSS 0.003382881 W [[2.2834055]] bias [3.7364929]\n",
      "[0115] LOSS 0.003380692 W [[2.283269]] bias [3.73692]\n",
      "[0116] LOSS 0.0033787265 W [[2.2831397]] bias [3.7373254]\n",
      "[0117] LOSS 0.0033769682 W [[2.2830172]] bias [3.7377098]\n",
      "[0118] LOSS 0.0033753768 W [[2.282901]] bias [3.7380743]\n",
      "[0119] LOSS 0.0033739544 W [[2.2827907]] bias [3.73842]\n",
      "[0120] LOSS 0.0033726902 W [[2.2826862]] bias [3.7387478]\n",
      "[0121] LOSS 0.0033715137 W [[2.2825868]] bias [3.7390587]\n",
      "[0122] LOSS 0.003370485 W [[2.2824929]] bias [3.7393537]\n",
      "[0123] LOSS 0.0033695505 W [[2.2824037]] bias [3.739633]\n",
      "[0124] LOSS 0.0033687153 W [[2.282319]] bias [3.7398982]\n",
      "[0125] LOSS 0.00336794 W [[2.282239]] bias [3.7401497]\n",
      "[0126] LOSS 0.00336729 W [[2.2821627]] bias [3.7403882]\n",
      "[0127] LOSS 0.0033666722 W [[2.2820907]] bias [3.7406144]\n",
      "[0128] LOSS 0.003366122 W [[2.282022]] bias [3.7408288]\n",
      "[0129] LOSS 0.0033656221 W [[2.2819574]] bias [3.7410321]\n",
      "[0130] LOSS 0.0033651968 W [[2.2818959]] bias [3.741225]\n",
      "[0131] LOSS 0.0033647667 W [[2.2818375]] bias [3.7414079]\n",
      "[0132] LOSS 0.003364421 W [[2.2817822]] bias [3.7415812]\n",
      "[0133] LOSS 0.0033641148 W [[2.2817297]] bias [3.7417457]\n",
      "[0134] LOSS 0.003363809 W [[2.2816799]] bias [3.7419016]\n",
      "[0135] LOSS 0.0033635474 W [[2.281633]] bias [3.7420497]\n",
      "[0136] LOSS 0.003363308 W [[2.2815878]] bias [3.74219]\n",
      "[0137] LOSS 0.0033631113 W [[2.2815456]] bias [3.742323]\n",
      "[0138] LOSS 0.0033629115 W [[2.2815053]] bias [3.742449]\n",
      "[0139] LOSS 0.003362738 W [[2.2814672]] bias [3.7425687]\n",
      "[0140] LOSS 0.0033625842 W [[2.281431]] bias [3.7426822]\n",
      "[0141] LOSS 0.0033624463 W [[2.2813966]] bias [3.7427897]\n",
      "[0142] LOSS 0.0033623297 W [[2.281364]] bias [3.7428918]\n",
      "[0143] LOSS 0.0033622186 W [[2.2813332]] bias [3.7429886]\n",
      "[0144] LOSS 0.0033621148 W [[2.281304]] bias [3.7430804]\n",
      "[0145] LOSS 0.0033620142 W [[2.2812762]] bias [3.7431674]\n",
      "[0146] LOSS 0.0033619318 W [[2.2812498]] bias [3.74325]\n",
      "[0147] LOSS 0.0033618703 W [[2.281225]] bias [3.743328]\n",
      "[0148] LOSS 0.0033617956 W [[2.2812011]] bias [3.7434022]\n",
      "[0149] LOSS 0.0033617443 W [[2.281179]] bias [3.7434728]\n",
      "[0150] LOSS 0.0033616803 W [[2.2811573]] bias [3.7435396]\n",
      "[0151] LOSS 0.003361649 W [[2.2811372]] bias [3.743603]\n",
      "[0152] LOSS 0.0033615897 W [[2.2811182]] bias [3.743663]\n",
      "[0153] LOSS 0.0033615537 W [[2.2810998]] bias [3.74372]\n",
      "[0154] LOSS 0.0033615243 W [[2.2810826]] bias [3.7437742]\n",
      "[0155] LOSS 0.0033614864 W [[2.2810662]] bias [3.7438254]\n",
      "[0156] LOSS 0.003361465 W [[2.2810507]] bias [3.743874]\n",
      "[0157] LOSS 0.0033614405 W [[2.281036]] bias [3.74392]\n",
      "[0158] LOSS 0.0033614188 W [[2.281022]] bias [3.7439637]\n",
      "[0159] LOSS 0.0033614119 W [[2.281009]] bias [3.7440052]\n",
      "[0160] LOSS 0.0033613734 W [[2.2809963]] bias [3.7440445]\n",
      "[0161] LOSS 0.0033613667 W [[2.2809844]] bias [3.7440817]\n",
      "[0162] LOSS 0.0033613562 W [[2.2809732]] bias [3.744117]\n",
      "[0163] LOSS 0.00336134 W [[2.2809625]] bias [3.7441504]\n",
      "[0164] LOSS 0.0033613201 W [[2.2809525]] bias [3.744182]\n",
      "[0165] LOSS 0.003361314 W [[2.2809427]] bias [3.7442122]\n",
      "[0166] LOSS 0.0033613096 W [[2.2809339]] bias [3.7442408]\n",
      "[0167] LOSS 0.003361297 W [[2.280925]] bias [3.7442677]\n",
      "[0168] LOSS 0.0033612899 W [[2.280917]] bias [3.7442935]\n",
      "[0169] LOSS 0.0033612722 W [[2.2809093]] bias [3.7443178]\n",
      "[0170] LOSS 0.0033612805 W [[2.2809017]] bias [3.744341]\n",
      "[0171] LOSS 0.0033612694 W [[2.2808948]] bias [3.7443628]\n",
      "[0172] LOSS 0.003361255 W [[2.280888]] bias [3.7443836]\n",
      "[0173] LOSS 0.0033612524 W [[2.280882]] bias [3.7444034]\n",
      "[0174] LOSS 0.0033612736 W [[2.280876]] bias [3.744422]\n",
      "[0175] LOSS 0.003361263 W [[2.2808702]] bias [3.7444396]\n",
      "[0176] LOSS 0.003361262 W [[2.280865]] bias [3.7444565]\n",
      "[0177] LOSS 0.0033612414 W [[2.28086]] bias [3.7444725]\n",
      "[0178] LOSS 0.0033612265 W [[2.280855]] bias [3.7444875]\n",
      "[0179] LOSS 0.003361246 W [[2.2808504]] bias [3.7445018]\n",
      "[0180] LOSS 0.0033612452 W [[2.280846]] bias [3.7445154]\n",
      "[0181] LOSS 0.0033612358 W [[2.280842]] bias [3.7445283]\n",
      "[0182] LOSS 0.0033612368 W [[2.280838]] bias [3.7445405]\n",
      "[0183] LOSS 0.0033612275 W [[2.2808344]] bias [3.7445521]\n",
      "[0184] LOSS 0.0033612133 W [[2.2808309]] bias [3.744563]\n",
      "[0185] LOSS 0.0033612219 W [[2.2808275]] bias [3.7445736]\n",
      "[0186] LOSS 0.003361219 W [[2.2808244]] bias [3.7445836]\n",
      "[0187] LOSS 0.003361233 W [[2.2808213]] bias [3.744593]\n",
      "[0188] LOSS 0.0033612214 W [[2.2808187]] bias [3.744602]\n",
      "[0189] LOSS 0.0033612333 W [[2.2808156]] bias [3.7446103]\n",
      "[0190] LOSS 0.0033612275 W [[2.2808135]] bias [3.7446184]\n",
      "[0191] LOSS 0.0033612128 W [[2.2808108]] bias [3.7446258]\n",
      "[0192] LOSS 0.0033612177 W [[2.2808084]] bias [3.744633]\n",
      "[0193] LOSS 0.0033612228 W [[2.2808065]] bias [3.7446399]\n",
      "[0194] LOSS 0.0033612163 W [[2.2808044]] bias [3.7446463]\n",
      "[0195] LOSS 0.0033612135 W [[2.2808025]] bias [3.7446525]\n",
      "[0196] LOSS 0.0033612237 W [[2.2808003]] bias [3.7446582]\n",
      "[0197] LOSS 0.003361219 W [[2.280799]] bias [3.744664]\n",
      "[0198] LOSS 0.0033612151 W [[2.280797]] bias [3.7446692]\n",
      "[0199] LOSS 0.00336123 W [[2.2807956]] bias [3.7446742]\n",
      "[0200] LOSS 0.0033612153 W [[2.280794]] bias [3.744679]\n",
      "[0201] LOSS 0.0033612116 W [[2.2807925]] bias [3.7446835]\n",
      "[0202] LOSS 0.0033612163 W [[2.2807913]] bias [3.7446878]\n",
      "[0203] LOSS 0.003361222 W [[2.2807896]] bias [3.7446916]\n",
      "[0204] LOSS 0.003361214 W [[2.280789]] bias [3.7446957]\n",
      "[0205] LOSS 0.0033612258 W [[2.2807872]] bias [3.7446992]\n",
      "[0206] LOSS 0.003361222 W [[2.2807865]] bias [3.7447028]\n",
      "[0207] LOSS 0.003361227 W [[2.280785]] bias [3.744706]\n",
      "[0208] LOSS 0.003361222 W [[2.2807844]] bias [3.744709]\n",
      "[0209] LOSS 0.0033612244 W [[2.2807834]] bias [3.7447119]\n",
      "[0210] LOSS 0.003361214 W [[2.2807825]] bias [3.7447147]\n",
      "[0211] LOSS 0.0033612177 W [[2.2807817]] bias [3.7447174]\n",
      "[0212] LOSS 0.0033612151 W [[2.2807808]] bias [3.7447197]\n",
      "[0213] LOSS 0.0033612098 W [[2.2807803]] bias [3.7447221]\n",
      "[0214] LOSS 0.0033612098 W [[2.2807794]] bias [3.7447243]\n",
      "[0215] LOSS 0.0033612177 W [[2.280779]] bias [3.7447264]\n",
      "[0216] LOSS 0.0033612226 W [[2.2807782]] bias [3.7447283]\n",
      "[0217] LOSS 0.0033612188 W [[2.2807777]] bias [3.7447302]\n",
      "[0218] LOSS 0.0033612163 W [[2.280777]] bias [3.744732]\n",
      "[0219] LOSS 0.003361214 W [[2.2807765]] bias [3.7447336]\n",
      "[0220] LOSS 0.0033612135 W [[2.280776]] bias [3.7447352]\n",
      "[0221] LOSS 0.0033612184 W [[2.2807755]] bias [3.7447367]\n",
      "[0222] LOSS 0.0033612084 W [[2.280775]] bias [3.744738]\n",
      "[0223] LOSS 0.0033612133 W [[2.2807746]] bias [3.7447395]\n",
      "[0224] LOSS 0.0033612116 W [[2.280774]] bias [3.744741]\n",
      "[0225] LOSS 0.0033612126 W [[2.2807739]] bias [3.7447422]\n",
      "[0226] LOSS 0.0033612172 W [[2.2807734]] bias [3.7447433]\n",
      "[0227] LOSS 0.0033612184 W [[2.280773]] bias [3.7447445]\n",
      "[0228] LOSS 0.0033612116 W [[2.2807727]] bias [3.7447457]\n",
      "[0229] LOSS 0.003361209 W [[2.2807722]] bias [3.7447467]\n",
      "[0230] LOSS 0.0033612251 W [[2.2807722]] bias [3.7447476]\n",
      "[0231] LOSS 0.0033612153 W [[2.2807715]] bias [3.7447484]\n",
      "[0232] LOSS 0.0033612158 W [[2.2807717]] bias [3.7447493]\n",
      "[0233] LOSS 0.0033612177 W [[2.2807713]] bias [3.74475]\n",
      "[0234] LOSS 0.0033612251 W [[2.280771]] bias [3.7447507]\n",
      "[0235] LOSS 0.003361219 W [[2.2807708]] bias [3.7447515]\n",
      "[0236] LOSS 0.0033612126 W [[2.2807705]] bias [3.7447522]\n",
      "[0237] LOSS 0.003361237 W [[2.2807705]] bias [3.744753]\n",
      "[0238] LOSS 0.0033612247 W [[2.28077]] bias [3.7447534]\n",
      "[0239] LOSS 0.003361199 W [[2.28077]] bias [3.744754]\n",
      "[0240] LOSS 0.0033612032 W [[2.2807698]] bias [3.7447546]\n",
      "[0241] LOSS 0.0033612147 W [[2.2807696]] bias [3.744755]\n",
      "[0242] LOSS 0.003361217 W [[2.2807696]] bias [3.7447555]\n",
      "[0243] LOSS 0.0033612126 W [[2.2807693]] bias [3.744756]\n",
      "[0244] LOSS 0.0033612153 W [[2.280769]] bias [3.7447565]\n",
      "[0245] LOSS 0.0033612133 W [[2.280769]] bias [3.744757]\n",
      "[0246] LOSS 0.0033612163 W [[2.280769]] bias [3.7447574]\n",
      "[0247] LOSS 0.0033612133 W [[2.2807686]] bias [3.7447577]\n",
      "[0248] LOSS 0.0033612202 W [[2.2807689]] bias [3.7447581]\n",
      "[0249] LOSS 0.0033612107 W [[2.2807686]] bias [3.7447584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0250] LOSS 0.0033612256 W [[2.2807684]] bias [3.7447586]\n",
      "[0251] LOSS 0.0033612133 W [[2.2807686]] bias [3.744759]\n",
      "[0252] LOSS 0.0033612147 W [[2.2807682]] bias [3.7447593]\n",
      "[0253] LOSS 0.0033612177 W [[2.2807682]] bias [3.7447598]\n",
      "[0254] LOSS 0.0033612265 W [[2.2807682]] bias [3.74476]\n",
      "[0255] LOSS 0.00336124 W [[2.280768]] bias [3.7447603]\n",
      "[0256] LOSS 0.0033612172 W [[2.280768]] bias [3.7447605]\n",
      "[0257] LOSS 0.0033612177 W [[2.280768]] bias [3.7447608]\n",
      "[0258] LOSS 0.003361211 W [[2.280768]] bias [3.744761]\n",
      "[0259] LOSS 0.003361227 W [[2.2807677]] bias [3.7447612]\n",
      "[0260] LOSS 0.0033612088 W [[2.2807677]] bias [3.7447615]\n",
      "[0261] LOSS 0.0033612098 W [[2.2807674]] bias [3.7447617]\n",
      "[0262] LOSS 0.003361214 W [[2.2807677]] bias [3.744762]\n",
      "[0263] LOSS 0.003361208 W [[2.2807672]] bias [3.744762]\n",
      "[0264] LOSS 0.0033612072 W [[2.2807674]] bias [3.7447622]\n",
      "[0265] LOSS 0.0033612065 W [[2.2807672]] bias [3.7447624]\n",
      "[0266] LOSS 0.0033612095 W [[2.2807674]] bias [3.7447627]\n",
      "[0267] LOSS 0.003361214 W [[2.2807672]] bias [3.7447627]\n",
      "[0268] LOSS 0.0033612188 W [[2.2807672]] bias [3.744763]\n",
      "[0269] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0270] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0271] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0272] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0273] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0274] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0275] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0276] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0277] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0278] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0279] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0280] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0281] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0282] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0283] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0284] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0285] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0286] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0287] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0288] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0289] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0290] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0291] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0292] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0293] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0294] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0295] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0296] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0297] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0298] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0299] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0300] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0301] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0302] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0303] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0304] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0305] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0306] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0307] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0308] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0309] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0310] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0311] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0312] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0313] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0314] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0315] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0316] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0317] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0318] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0319] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0320] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0321] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0322] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0323] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0324] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0325] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0326] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0327] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0328] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0329] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0330] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0331] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0332] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0333] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0334] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0335] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0336] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0337] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0338] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0339] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0340] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0341] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0342] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0343] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0344] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0345] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0346] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0347] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0348] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0349] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0350] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0351] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0352] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0353] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0354] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0355] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0356] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0357] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0358] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0359] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0360] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0361] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0362] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0363] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0364] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0365] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0366] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0367] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0368] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0369] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0370] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0371] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0372] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0373] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0374] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0375] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0376] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0377] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0378] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0379] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0380] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0381] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0382] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0383] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0384] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0385] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0386] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0387] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0388] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0389] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0390] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0391] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0392] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0393] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0394] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0395] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0396] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0397] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0398] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0399] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0400] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0401] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0402] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0403] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0404] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0405] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0406] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0407] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0408] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0409] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0410] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0411] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0412] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0413] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0414] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0415] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0416] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0417] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0418] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0419] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0420] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0421] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0422] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0423] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0424] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0425] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0426] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0427] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0428] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0429] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0430] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0431] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0432] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0433] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0434] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0435] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0436] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0437] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0438] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0439] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0440] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0441] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0442] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0443] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0444] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0445] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0446] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0447] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0448] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0449] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0450] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0451] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0452] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0453] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0454] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0455] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0456] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0457] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0458] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0459] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0460] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0461] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0462] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0463] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0464] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0465] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0466] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0467] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0468] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0469] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0470] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0471] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0472] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0473] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0474] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0475] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0476] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0477] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0478] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0479] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0480] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0481] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0482] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0483] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0484] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0485] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0486] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0487] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0488] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0489] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0490] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0491] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0492] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0493] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0494] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0495] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0496] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0497] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0498] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n",
      "[0499] LOSS 0.0033612163 W [[2.2807672]] bias [3.744763]\n"
     ]
    }
   ],
   "source": [
    "# Session 시작\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(500):\n",
    "  res, cost  = sess.run([training, cost_function],\n",
    "                        feed_dict={X: xtrain, Y:ytrain})\n",
    "  if cost < 0.003:\n",
    "    break\n",
    "\n",
    "  if i % 1 == 0:\n",
    "    y2, w, b = sess.run([Y2, W, B], feed_dict={X: xtrain, Y: ytrain})\n",
    "    print('[%04d]' % i, 'LOSS', cost, 'W', w, 'bias', b)\n",
    "\n",
    "    history.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss 값의 변화 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1213316a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy and cost summaries\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.plot(history[:10])    # GradientDescentOptimizer\n",
    "ax.set_title('optimizer')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터에 대한 정확도 확인 (학습 오차 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.83  3.88 오차율 1.23 %\n",
      "4.27  4.24 오차율 0.79 %\n",
      "4.47  4.50 오차율 0.65 %\n",
      "5.28  5.30 오차율 0.29 %\n",
      "5.61  5.62 오차율 0.23 %\n",
      "5.79  5.67 오차율 2.21 %\n",
      "6.98  6.94 오차율 0.50 %\n",
      "7.15  7.21 오차율 0.88 %\n",
      "8.83  8.87 오차율 0.48 %\n",
      "9.38  9.36 오차율 0.21 %\n",
      "9.99  10.01 오차율 0.22 %\n",
      "10.02  9.93 오차율 0.92 %\n",
      "10.05  10.15 오차율 0.99 %\n",
      "11.20  11.12 오차율 0.73 %\n",
      "11.71  11.73 오차율 0.11 %\n",
      "12.04  12.14 오차율 0.80 %\n",
      "13.00  12.96 오차율 0.31 %\n",
      "13.21  13.17 오차율 0.30 %\n",
      "13.65  13.64 오차율 0.09 %\n",
      "14.48  14.51 오차율 0.23 %\n"
     ]
    }
   ],
   "source": [
    "[y_from_nn] = sess.run([Y2], feed_dict={X: xtrain})\n",
    "\n",
    "for y_nn, y_real in zip(y_from_nn, ytrain):\n",
    "    err = abs(y_nn[0] - y_real) / y_real * 100\n",
    "    print('%.2f  %.2f 오차율 %.2f %%' % (y_nn[0], y_real, err))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unseen = [random.random() * XVALUE for i in range(NUM_DATA)]\n",
    "x_unseen = np.array(x_unseen).reshape((NUM_DATA, 1))\n",
    "\n",
    "y_unseen = sess.run([Y2], feed_dict={X: x_unseen})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12134cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xtrain, ytrain, label='train')\n",
    "ax.scatter(x_unseen, y_unseen, label='unseen')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
